# 1.9 部署相关库的安装

如果想要大规模抓取数据，那么一定会用到分布式爬虫，对于分布式爬虫来说，我们一定需要多台主机，每台主机多个爬虫任务，但是源代码其实只有一份。那么我们需要做的就是将一份代码同时部署到多台主机上来协同运行，那么怎么去部署就又是一个值得思考的问题。

对于Scrapy来说，它有一个扩展组件叫做Scrapyd，我们只需要安装Scrapyd即可远程管理Scrapy任务，包括部署源码、启动任务、监听任务等操作。另外还有ScrapydClient和ScrapydAPI来帮助我们更方便地完成部署和监听操作。

另外还有一种部署方式就是Docker集群部署，我们只需要将爬虫制作为Docker镜像，只要主机安装了Docker，就可以直接运行爬虫，而无需再去担心环境配置、版本问题。

本节我们就来介绍一下相关环境的配置过程。